---
title: "Avanced structural equation modeling"
date: "04.01.2024"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
header-includes:
   - \usepackage{svg}
editor_options:
  chunk_output_type: console
bibliography:
  - "`r system('kpsewhich ../references.bib', intern = TRUE)`"
biblio-style: apalike
link-citations: yes
linkcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("here")
library(tidyverse)
```



# Load data and re-run the model
Here, we use the very same data set as in the introductory part to SEM (`1_basic_modeling.html`).
Also, we rescale the biomass and precipitation so that they are in approximately the same range as the other variables.


```{r}
seabloom <- read.table(here("2_Modeling/Data_preparation/seabloom-2020-ele-dryad-data/cdr-e001-e002-output-data.csv"),
                       sep = ",", header = TRUE)

# take average across all years to avoid pseude-replication issues
seabloom <- seabloom %>% group_by(exp, field, plot, disk, yr.plowed, ntrt, nadd, other.add) %>% summarise(across(mass.above:ens.pie, mean))

# rescale AGB variable to faciliate convergence
seabloom$mass.above <- seabloom$mass.above / 100
```

## Rerun the model
First, we run the model as before.


![](Figures/SimpleSEM.svg){width=60%}


```{r}
library("lavaan")

simple <-
"mass.above ~ nadd + rich + even + disk
rich ~ nadd 
even ~ nadd

rich ~~ even"

fit.simple <- sem(simple, data = seabloom, estimator = "MLM")
summary(fit.simple)
```

# Latent and composite variables

**Latent variables** represent unmeasured variables that are represented by their  indicator variables^[Indicator variables are observed/manifest variables that are linked to either a latent or composite variable.] [@bollen89]. As a consequence, a latent variable is free of  random or systematic measurement errors in contrast to its indicators [@bollen89].
They have a special role in SEM because they represent a kind of bridge between observed data and theoretical generalization [@grace08].

Usually, they are visualized by arrows pointing from the latent variable to the indicators (so-called "reflective" [@grace21]).
This symbolizes the underlying process that generated the indicators. In other words, latent variables give rise to their indicators.
Often, ellipses are used to denote a latent variable.


**Composites** are another type of variables which represent the collective effects of a set of causes on some response variable(s) [@grace08].
In comparison to latent variables, they arise from the indicators. For this reason, they are visualized by arrows pointing from the indicators to the composite (so-called "formative" [@grace21] or "causal indicators" [@grace10]).
In that respect, they represent a collective effect (e.g., the collective effect of the abiotic environment).
Since its values are determined by its causes (indicators), the error variance is specified to be 0 [@grace08]. Thus, they are technically latent variables without variance [@grace21].
Composites are often symbolized by hexangular shapes or--the same as for latent variables--by ellipses.


**Key differences** between them are [@grace08]:

1. The flow of causation in a latent variables is from the construct to its indicators, meaning that the indicators are driven by an underlying, unmeasured process, the latent variable. In the case of a composite variable, the flow of causation is reversed and the indicators are independent entities no matter the construct.
<!-- * we ask whether “Soil” has causal influences on pH, moisture, and texture. In other words, we are asking whether the variation among stands in soil conditions is such that pH, moisture, and texture are simultaneously being controlled by a common difference among soils. If so, causation flows from the construct to the indicators. Alternatively, if it is the case that pH, moisture, and texture behave inde-pendently from one another, then causation flows from the indicators to the construct. -->
1. If the indicators are redundant, they likely belong to a latent variable. If the meaning of the construct changes after dropping one of the indicators, the construct likely is a composite.
<!-- * The second question is whether the indicators in a block are interchangeable, if so, then they constitute redundant measures and are likely to represent effect indicators consistent with a L → M block. Also, we might ask if dropping one of the indicators in a block alters the meaning of the construct. -->
1. As a latent variable represents an underlying, data-generating process, its indicators need to be correlated to each other. In the case of a composite variable, there is no assumption about the relation between the indicators. Thus, correlation among indicators are uninformative about the direction of the causal flow, but a lack of such contraindicates that the construct is a latent variable.
<!-- * We should, therefore, recognize that a correlation among indicators does not inform us as to the direction of causal flow, though a lack of correlation among indicators would contraindicate the prospect that a block should be of the L → M form. -->

Carried over to our example, we measured instances of the general process "diversity" (richness, evenness etc.).
Further, we summarize the abiotic condition (nutrient addition, precipitation etc.) of a plot in a composite variable.


![](Figures/LatentCompositeSEM.svg){width=50%}


# Latent variable
Let's first create a latent variable "diversity" from the three measurements of diversity (richness, evenness and ENS~PIE~).

Latent variable models are usually evaluated in two stages:
first the fit between the latent variables and their indicators ([confirmatory factor analysis (CFA)](https://en.wikipedia.org/wiki/Confirmatory_factor_analysis)), second the full model [@grace21a].

## Correlations between indicators
Indicators for a LV should be positively correlated with each other. If we fail to find significant correlations based on standard tests and null hypothesis testing, we reject the hypothesis that the indicators are varying in concert and the data contradicts the claim of a latent cause [@grace21a].


```{r}
cor.test(seabloom$even, seabloom$rich)
cor.test(seabloom$ens.pie, seabloom$rich)
cor.test(seabloom$even, seabloom$ens.pie)
## Not that surprising that there is no correlation...
plot(seabloom$ens.pie, seabloom$even)
```

To ease convergence of the algorithm, we reverse the orientation of evenness as it is negatively correlated with richness (so that absolute evenness is found at 0, while absolute unevenness is found at 1):

```{r}
seabloom$even.rev <- 1 - seabloom$even
cor.test(seabloom$even.rev, seabloom$rich)
cor.test(seabloom$ens.pie, seabloom$even.rev)
```


## Confirmatory factor analysis

Let's start with the CFA:

```{r}
diversity <- 'div =~ rich + even.rev + ens.pie'

fit.diversity <- cfa(diversity, data = seabloom, estimator = "MLM")
summary(fit.diversity, standardized=T, rsq=T)

varTable(fit.diversity)
```

Parameter estimates taking improper solution, i.e. impossible values, are a sign of model misspecification.
The occurrence of negative variances, as we see here, is known as "Heywood case". Another improper solution would be correlations larger than one [@bollen89].
Reasons for the current warning could be
(i) slightly negative error estimates (what would not really be a problem),
(ii) the need to code indicators for the latent variable to be positively related,
(iii) local non-identification or
(iv) general misspecification [@grace21].

Here we clearly have a problem with model mis-specification. According to (@seabloom20), the variable ens.pie is the product of evenness and species richness. This causes the model to fail. Therefore let's abandon the ens.pie variable for a moment and focus on a two indicator latent variable.

Latent variable models with only 2 indicators are locally non-identified because we only have one piece of information (their correlation) to estimate two path coefficients. To solve this problem, we can (a) ensure x1 and x2 have equal variances, in this case by standardizing the data. (2) When latent variables are included we must specify a fixed value for some parameter associated with the LV to achieve identification. The lavaan default is to set the loading from the LV to the first-mentioned indicator to 1.0. (3) For single-indicator LVs, the default measurement error is set to 0.0 [@grace21].

Here we standardize the two variables and then estimate a single path coefficient by forcing a single coefficient for both indicators:

```{r}
seabloom$rich_std <- (mean(seabloom$rich)-seabloom$rich) / sd(seabloom$rich)
seabloom$even.rev_std <- (mean(seabloom$even.rev)-seabloom$even.rev) / sd(seabloom$even.rev)

diversity <- 'div =~ lambda*rich_std + lambda*even.rev_std'

fit.diversity <- cfa(diversity, data = seabloom, estimator = "MLM")
summary(fit.diversity, standardized=T)
```

This worked, all variances are positive and we get a single coefficient for the effects of diversity on richness and evenness. As the model is just identified, we do not have a possibility to test model fit.

## Full model
Now, let's evaluate the full model including the latent variable as well as the remaining variables.

```{r}
lv <- '
# Latent variable definition
diversity =~ lambda*even.rev_std + lambda*rich_std

mass.above ~ nadd + disk + diversity 
diversity ~ nadd 
'

fit.lv <- sem(lv, data = seabloom, estimator = "MLM")
summary(fit.lv)
```

The model converged and the fit is good. The coefficients suggest effects of nutrient addition and precipitation on diversity. However, we would expect a negative effect of nutrient addition on diversity, while the effect is positive. The opposite expectation would hold for diversity on AGB, but here we see a negative effect. Can you explain why this is the case?

Right, it has to do with reversing the direction of the evenness effect. As both richness and reversed evenness influence AGB, the meaning of the latent diversity effect is reversed. We can see this when we fit a model that just contains the ens.pie variable:

```{r}
lv <- '
mass.above ~ nadd + disk + ens.pie 
ens.pie ~ nadd
'

fit.lv <- sem(lv, data = seabloom, estimator = "MLM")
summary(fit.lv)
```

As you can see, now the joint effect of evenness and richness is negatively influenced by nutrient addition and AGB is positivelyaffected by diversity. The model is also fitting the data pretty well.


# Composite variable

Composite variables are another type of variable that make the SEM framework very flexible. As described above, composite variables specify the influence of collections of other variables. In comparison to latent variables, they arise from the indicators. They are hence visualized by arrows pointing from the indicators to the composite (formative or causal indicators). Composite variables are a great means to ease the interpretation of multiple indicators at once.

## Landuse composite
To model the collective effect of the treatment, let's create a "landuse" composite variable that accounts for both the disturbance and nutrient addition.
To save one parameter, we fix the `disk` at one--now the model is just identified.

```{r}
comp <- "
comp.landuse <~ 1 * disk + nadd

rich ~  comp.landuse
even ~  comp.landuse
mass.above ~ comp.landuse + rich + even

rich ~~ even"

fit.comp <- sem(comp, data = seabloom)
summary(fit.comp, standardized=T)
```


### Manually compute composite
Sometimes `lavaan` struggles to fit models with composites. In such cases, the composites can be first calculated manually and then incorporated into the model as a regular variable [@grace21].

First, we specify and fit a model containing only the indicators and the response.

```{r}
comp.man <- 'mass.above ~ disk + nadd'
fit.comp.man <- sem(comp.man, data = seabloom)
summary(fit.comp.man)
```

Then, we compute the composite scores by taking the sum of all indicator variables multiplied by their estimates.

```{r}
seabloom$landuse <- lavInspect(fit.comp.man, what = "est")$beta[1, 2] * seabloom$disk +
  lavInspect(fit.comp.man, what = "est")$beta[1, 3] * seabloom$nadd
```

Fitting this newly calculated variable `landuse` to the response `mass.above`...

```{r}
comp.man2 <- "mass.above ~ landuse"
fit.comp.man2 <- sem(comp.man2, data = seabloom)
```

... yields the same standardized coefficient and R^2^ for `mass.above` as above.

```{r}
lavInspect(fit.comp.man, "std.nox")$psi[1, 1]
lavInspect(fit.comp.man2, "std.nox")$psi[1, 1]

lavInspect(fit.comp.man, "rsquare")
lavInspect(fit.comp.man2, "rsquare")
```

Finally, we can integrate the composite `landuse` into the `simple` model from before.

```{r}
comp <- "
rich ~  landuse
even ~ landuse

mass.above ~ landuse + rich + even

rich ~~ even"

fit.comp <- sem(comp, data = seabloom)
summary(fit.comp, standardized=T)
```

When you compare the estimates of the composites fitted automatically or manually, you see that they are very close, as is expected.

## Interactions

In nature, things often are contingent on each other. For instance, the effect of nutrients on plant growth, may depend on how disturbed the environment is. Such a behaviour is called an interaction, which indicates that the effect of the two main effects are different when combined.  

![](Figures/Interaction.svg){width=50%}

First, let's visually inspect the hypothesized interaction between the effect of disturbance on above-ground biomass and the amount of nutrients.

```{r}
library("ggplot2")
theme_set(theme_bw())


ggplot(aes(disk, mass.above, group = disk), data = seabloom) +
  geom_boxplot() +
  facet_grid( ~ nadd) +
  scale_x_continuous(breaks = c(0, 1)) +
  xlab("Disturbance") +
  ylab("Above-ground biomass [g/m²]")
```

It seems that the higher the amount of added nutrients, the higher the gap in above-ground biomass between the disturbed and undisturbed plots.

### Modeling the interaction
![](Figures/Interaction_Composite.svg){width=50%}

In regression, the interaction is represented by a coefficient that estimates the effect of the product of the two predictors. Let's create this new variable and call it diskxnadd.   

```{r}
seabloom$diskxnadd <- seabloom$disk * seabloom$nadd

int <- "mass.above ~ disk + nadd + diskxnadd"
fit.int <- sem(int, data = seabloom)
summary(fit.int)
```

The results show a significant effect of both variables and their interaction.

Next, we model them as a composite:

```{r}
compint <-
"comp.int <~ 1 * disk + nadd + diskxnadd
mass.above ~ comp.int"

fit.compint <- sem(compint, data = seabloom)
summary(fit.compint, standardized = TRUE)
```

The combined effect of the predictors is the `std.all` value for the regression (`r round(lavInspect(fit.compint, what = "std.all")$beta[2, 1], digits = 3)`).

### Full model
```{r}
int.full <-
"comp.int <~ 1 * disk + nadd + diskxnadd

mass.above ~ comp.int + rich + even
rich ~ nadd
even ~ nadd 

rich ~~ even"

fit.int.full <- sem(int.full, data = seabloom)
summary(fit.int.full, fit.measures = TRUE, standardized = TRUE, rsq = TRUE)
```

Not the greatest fit in terms of $p$-value (`r round(fitmeasures(fit.int.full, "pvalue"), digits = 2)`), but really fine in terms of CFI (`r round(fitmeasures(fit.int.full, "cfi"), digits = 3)`).

## Multigroup fitting 

Another way to incorporate interactions is to fit SEMs where coefficients can vary among groups. Lavaan offers the "group" argument to specify for which groups coefficients should be estimated. Importantly, groups have to be of categorical nature. For our dataset, the application of the disturbance ("yes" vs "no") is categorical. So let's fit the SEM to the two disturbance regimes:

```{r}
int.mg <-
"mass.above ~ rich + even 
rich ~ nadd 
even ~ nadd

rich ~~ even"

fit.int.mg <- sem(int.mg, group = "disk", data = seabloom)
summary(fit.int.mg, standardized = TRUE, rsq = TRUE)
```

The default option is to let all coefficients vary between groups, but have the same structure of direct and indirect effects. Let's visualize the estimated coefficients:

```{r, results=F}
fit_tab <- (summary(fit.int.mg, standardized = TRUE, rsq = TRUE))$pe
fit_tab$term <- paste0(fit_tab$lhs, " ", fit_tab$op, " ", fit_tab$rhs)
fit_tab$group_chr <- ifelse(fit_tab$group == 1, "undist", 
                            ifelse(fit_tab$group == 2, "dist", NA))

ggplot(data=subset(fit_tab, op == "~"), aes(y=est, x=group_chr, colour=group_chr)) + 
  geom_point(size=1) + geom_errorbar(aes(ymin = est-se*1.96, ymax = est+se*1.96)) + 
  facet_wrap(~term, scales="free") + 
  scale_colour_manual(values = c("blue",  "red")) + 
  geom_hline(aes(yintercept = 0), colour = "black", linetype = "dashed") + 
  guides(colour="none") +
  theme_bw() 
```

Each facet grid shows a path and the estimated coefficients, one for disturbed (in blue) and one for the undisturbed plots (in red).

To test equality constraints, such as same means of coefficients among groups, lavaan offers the "group.equal" argument:

```{r, results = 'asis'}
group.equal=c(
"intercepts",
"means",
"regressions",
"residuals",
"residual.covariances")

#fit.int.mg <- sem(int.mg, group = "disk", group.equal = c("regressions"), data = seabloom)
```

Furthermore, we can test equality constraints by labeling parameters. To do so, we provide namees for the path coefficients that we want to be equal for both groups (e.g. "b1"), whereas path coefficients that we want to vary between groups have different names (e.g., "b4a" and "b4b").

```{r}
int.mg.constrain <-
"mass.above ~  c('b1', 'b1') * rich + c('b2', 'b2') * even
rich ~ c('b4a', 'b4b') * nadd 
even ~ c('b6a', 'b6b') *  nadd 

rich ~~ even"

fit.int.mg.constrain <- sem(int.mg.constrain, group = "disk", data = seabloom)
summary(fit.int.mg.constrain, standardized = TRUE, rsq = TRUE)
```

Let's visualize again the coefficients to see the effect:

```{r, results=F}
fit_tab <- (summary(fit.int.mg.constrain, standardized = TRUE, rsq = TRUE))$pe
fit_tab$term <- paste0(fit_tab$lhs, " ", fit_tab$op, " ", fit_tab$rhs)
fit_tab$group_chr <- ifelse(fit_tab$group == 1, "undist", 
                            ifelse(fit_tab$group == 2, "dist", NA))

ggplot(data=subset(fit_tab, op == "~"), aes(y=est, x=group_chr, colour=group_chr)) + 
  geom_point(size=1) + geom_errorbar(aes(ymin = est-se*1.96, ymax = est+se*1.96)) + 
  facet_wrap(~term, scales="free") + 
  scale_colour_manual(values = c("blue",  "red")) + 
  geom_hline(aes(yintercept = 0), colour = "black", linetype = "dashed") + 
  guides(colour="none") +
  theme_bw() 
```

Model comparison with AICc indicates that the disturbance effect probably interacts with more than the nitrogen addition. 

```{r}
library(AICcmodavg)
aictab(list(fit.int.mg, fit.int.mg.constrain))
```

# References

