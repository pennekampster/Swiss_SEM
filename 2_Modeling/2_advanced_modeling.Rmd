---
title: "Avanced structural equation modeling"
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
header-includes:
   - \usepackage{svg}
editor_options:
  chunk_output_type: console
bibliography:
  - "`r system('kpsewhich ../references.bib', intern = TRUE)`"
biblio-style: apalike
link-citations: yes
linkcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("here")
```



# Load data and re-run the model
Here, we use the very same data set as in the introductory part to SEM (`1_basic_modeling.html`).
Also, we rescale the biomass and precipitation so that they are in approximately the same range as the other variables.


```{r}
seabloom <- read.table(here("2_Modeling/Data_preparation/seabloom-2020-ele-dryad-data/cdr-e001-e002-output-data.csv"),
                       sep = ",", header = TRUE)

#seabloom <- subset(seabloom, year >= 2000)
seabloom$rich <- seabloom$rich

seabloom$mass.above <- seabloom$mass.above / 100
seabloom$precip.mm <- seabloom$precip.mm / 100
seabloom$precip.gs <- seabloom$precip.gs / 100


# remove_outliers <- function(x, na.rm = TRUE, ...) {
#   qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
#   H <- 1.5 * IQR(x, na.rm = na.rm)
#   y <- x
#   y[x < (qnt[1] - H)] <- NA
#   y[x > (qnt[2] + H)] <- NA
#   y
# }
# 
# library(tidyverse)
# 
# seabloom <- seabloom %>% mutate(across(c(mass.above, precip.gs, precip.mm, rich, even), remove_outliers))
# seabloom <- na.omit(seabloom)  


```



## Rerun the model
First, we run the model as before.


![](Figures/SimplePrecSEM.svg){width=60%}


```{r}
library("lavaan")

simple <-
"mass.above ~ nadd + disk + rich + even + precip.mm
rich ~ nadd + precip.mm
even ~ nadd + precip.mm

rich ~~ even"

fit.simple <- sem(simple, data = seabloom, estimator = "MLM")
summary(fit.simple)
```

# Latent and composite variables

**Latent variables** represent unmeasured variables that are represented by their  indicator variables^[Indicator variables are observed/manifest variables that are linked to either a latent or composite variable.] [@bollen89]. As a consequence, a latent variable is free of  random or systematic measurement errors in contrast to its indicators [@bollen89].
They have a special role in SEM because they represent a kind of bridge between observed data and theoretical generalization [@grace08].

Usually, they are visualized by arrows pointing from the latent variable to the indicators (so-called "reflective" [@grace21] or "formative indicators" [@grace10]).
This symbolizes the underlying process that generated the indicators. In other words, latent variables give rise to their indicators.
Often, ellipses are used to denote a latent variable.


**Composites** are another type of variables which represent the collective effects of a set of causes on some response variable(s) [@grace08].
In comparison to latent variables, they arise from the indicators. For this reason, they are visualized by arrows pointing from the indicators to the composite (so-called "formative" [@grace21] or "causal indicators" [@grace10]).
In that respect, they represent a collective effect (e.g., the collective effect of the abiotic environment).
Since its values are determined by its causes (indicators), the error variance is specified to be 0 [@grace08]. Thus, they are technically latent variables without variance [@grace21].
Composites are often symbolized by hexangular shapes or--the same as for latent variables--by ellipses.


**Key differences** between them are [@grace08]:

1. The flow of causation in a latent variables is from the construct to its indicators, meaning that the indicators are driven by an underlying, unmeasured process, the latent variable. In the case of a composite variable, the flow of causation is reversed and the indicators are independent entities no matter the construct.
<!-- * we ask whether “Soil” has causal influences on pH, moisture, and texture. In other words, we are asking whether the variation among stands in soil conditions is such that pH, moisture, and texture are simultaneously being controlled by a common difference among soils. If so, causation flows from the construct to the indicators. Alternatively, if it is the case that pH, moisture, and texture behave inde-pendently from one another, then causation flows from the indicators to the construct. -->
1. If the indicators are redundant, they likely belong to a latent variable. If the meaning of the construct changes after dropping one of the indicators, the construct likely is a composite.
<!-- * The second question is whether the indicators in a block are interchangeable, if so, then they constitute redundant measures and are likely to represent effect indicators consistent with a L → M block. Also, we might ask if dropping one of the indicators in a block alters the meaning of the construct. -->
1. As a latent variable represents an underlying, data-generating process, its indicators need to be correlated to each other. In the case of a composite variable, there is no assumption about the relation between the indicators. Thus, correlation among indicators are uninformative about the direction of the causal flow, but a lack of such contraindicates that the construct is a latent variable.
<!-- * We should, therefore, recognize that a correlation among indicators does not inform us as to the direction of causal flow, though a lack of correlation among indicators would contraindicate the prospect that a block should be of the L → M form. -->

Carried over to our example, we measured instances of the general process "diversity" (richness, evenness etc.).
Further, we summarize the abiotic condition (nutrient addition, precipitation etc.) of a plot in a composite variable.


![](Figures/LatentCompositeSEM.svg){width=50%}


# Latent variable
Let's first create a latent variable "diversity" from the three measurements of diversity (richness, evenness and ENS~PIE~).

Indicators for a LV should be positively correlated with each other.

* Latent variable models with only 2 indicators are locally non-identified. To solve this problem, we can (a) ensure x1 and x2 have equal variances, in this case by standardizing the data. (2) When latent variables are included we must specify a fixed value for some parameter associated with the LV to achieve identification. The lavaan default is to set the loading from the LV to the first-mentioned indicator to 1.0. (3) For single-indicator LVs, the default measurement error is set to 0.0 [@grace21].


## Correlations between indicators
If we fail to find significant correlations based on standard tests and null hypothesis testing, we reject the hypothesis that the indicators are varying in concert and the data contradicts the claim of a latent cause [@grace21a].


```{r}
cor.test(seabloom$even, seabloom$rich)
cor.test(seabloom$ens.pie, seabloom$rich)
cor.test(seabloom$even, seabloom$ens.pie)
## Not that surprising that there is no correlation...
plot(seabloom$ens.pie, seabloom$even)
```

To ease convergence of the algorithm, we reverse the orientation of evenness as it is negatively correlated with richness (so that absolute evenness is found at 0, while absolute unevenness is found at 1):

```{r}
seabloom$even.rev <- 1 - seabloom$even
cor.test(seabloom$even.rev, seabloom$rich)
cor.test(seabloom$ens.pie, seabloom$even.rev)
```


## Confirmatory factor analysis
Latent variable models are usually evaluated in two stages:
first the fit between the latent variables and their indicators ([confirmatory factor analysis (CFA)](https://en.wikipedia.org/wiki/Confirmatory_factor_analysis)), second the full model [@grace21a].


```{r}
diversity <- 'div =~ rich + even.rev + ens.pie'

fit.diversity <- cfa(diversity, data = seabloom, estimator = "MLM")
summary(fit.diversity, standardized=T, rsq=T)

varTable(fit.diversity)
```

Parameter estimates taking improper solution, i.e. impossible values, are a sign of model misspecification.
The occurrence of negative variances, as we see here, is known as "Heywood case". Another improper solution would be correlations larger than one [@bollen89].
Reasons for the current warning could be
(i) slightly negative error estimates (what would not really be a problem),
(ii) the need to code indicators for the latent variable to be positively related,
(iii) local non-identification or
(iv) general misspecification [@grace21].

Here we clearly have a problem with model mis-specification. According to (@seabloom20), the variable ens.pie is the product of evenness and species richness. This causes the model to fail. Therefore let's abandon the ens.pie variable for a moment and focus on a two indicator latent variable.

Remember that two indicator latent variables are not identifiable because we only have one piece of information (their correlation) to estimate two path coefficients.

A possible solution is to standardize the two variables and then estimate a single path coefficient by forcing a single coefficient for both indicators:

```{r}
seabloom$rich_std <- (mean(seabloom$rich)-seabloom$rich) / sd(seabloom$rich)
seabloom$even.rev_std <- (mean(seabloom$even.rev)-seabloom$even.rev) / sd(seabloom$even.rev)

diversity <- 'div =~ lambda*rich_std + lambda*even.rev_std'

fit.diversity <- cfa(diversity, data = seabloom, estimator = "MLM")
summary(fit.diversity, standardized=T)
```

This worked, all variances are positive and we get a single coefficient for the effects of diversity on richness and evenness. As the model is just identified, we do not have a possibility to test model fit.

## Full model
Now, let's evaluate the full model including the latent variable as well as the remaining variables.

```{r}
lv <- '
# Latent variable definition
diversity =~ lambda*even.rev_std + lambda*rich_std

mass.above ~ nadd + disk + diversity + precip.mm
diversity ~ nadd + precip.mm
'

fit.lv <- sem(lv, data = seabloom, estimator = "MLM")
summary(fit.lv)
```

The model converged, but the model fit is not great. The coefficients suggest effects of nutrient addition and precipitation on diversity. However, we would expect a negative effect of nutrient addition, while the effect is positive. The opposite expectation would hold for precipitation, but here we see a negative effect. Can you explain why this is the case?

Right, it has to do with reversing the direction of the evenness effect. As both richness and reversed evenness influence AGB, the meaning of the latent diversity effect is reversed. We can see this when we fit a model that just contains the ens.pie variable:

```{r}
lv <- '
mass.above ~ nadd + disk + ens.pie + precip.mm
ens.pie ~ nadd + precip.mm
'

fit.lv <- sem(lv, data = seabloom, estimator = "MLM")
summary(fit.lv)
```

As you can see, now the joint effect of evenness and richness is negatively influenced by nutrient addition and positively (but non-significantly) by precipitation. The model is also fitting the data pretty well.


# Composite variable

Composite variables are another type of variable that make the SEM framework very flexible. As described above, composite variables specify the influence of collections of other variables. In comparison to latent variables, they arise from the indicators. They are hence visualized by arrows pointing from the indicators to the composite (formative or causal indicators). Composite variables are a great means to ease the interpretation of multiple indicators at once.

## Landuse composite
To model the collective effect of the treatment, let's create a "landuse" composite variable that accounts for both the disturbance and nutrient addition.
To save one parameter, we fix the `disk` at one--now the model is just identified.

```{r}
comp <- "
comp.landuse <~ 1 * disk + nadd

rich ~ precip.mm + comp.landuse
even ~ precip.mm + comp.landuse
mass.above ~ comp.landuse + rich + even + precip.mm

rich ~~ even"

fit.comp <- sem(comp, data = seabloom)
summary(fit.comp)
```


### Manually compute composite
Sometimes `lavaan` struggles to fit models with composites. In such cases, the composites can be first calculated manually and then incorporated into the model as a regular variable [@grace21].

First, we specify and fit a model containing only the indicators and the response.

```{r}
comp.man <- 'mass.above ~ disk + nadd'
fit.comp.man <- sem(comp.man, data = seabloom)
summary(fit.comp.man, rsq = TRUE, standardized = TRUE)
```

Then, we compute the composite scores by taking the sum of all indicator variables multiplied by their estimates.

```{r}
seabloom$landuse <- lavInspect(fit.comp.man, what = "est")$beta[1, 2] * seabloom$disk +
  lavInspect(fit.comp.man, what = "est")$beta[1, 3] * seabloom$nadd
```

Fitting this newly calculated variable `landuse` to the response `mass.above`...

```{r}
comp.man2 <- "mass.above ~ landuse"
fit.comp.man2 <- sem(comp.man2, data = seabloom)
```

... yields the same standardized coefficient and R^2^ for `mass.above` as above.

```{r}
lavInspect(fit.comp.man, "std.nox")$psi[1, 1]
lavInspect(fit.comp.man2, "std.nox")$psi[1, 1]

lavInspect(fit.comp.man, "rsquare")
lavInspect(fit.comp.man2, "rsquare")
```

Finally, we can integrate the composite `landuse` into the `simple` model from before.

```{r}
comp <- "
rich ~ landuse + precip.mm
even ~ landuse + precip.mm

mass.above ~ landuse + rich + even + precip.mm

rich ~~ even"

fit.comp <- sem(comp, data = seabloom)
summary(fit.comp)
```

## Interactions

In nature, things often are contingent on each other. For instance, the effect of nutrients on plant growth, may depend on how disturbed the environment is. Such a behaviour is called an interaction, which indicates that the effect of the two main effects are different when combined.  

![](Figures/Interaction.svg){width=50%}

First, let's visually inspect the hypothesized interaction between the effect of disturbance on above-ground biomass and the amount of nutrients.

```{r}
library("ggplot2")
theme_set(theme_bw())


ggplot(aes(disk, mass.above, group = disk), data = seabloom) +
  geom_boxplot() +
  facet_grid( ~ nadd) +
  scale_x_continuous(breaks = c(0, 1)) +
  xlab("Disturbance") +
  ylab("Above-ground biomass [g/m²]")
```

It seems that the higher the amount of added nutrients, the higher the gap in above-ground biomass between the disturbed and undisturbed plots.

### Modeling the interaction
![](Figures/Interaction_Composite.svg){width=50%}

In regression, the interaction is represented by a coefficient that estimates the effect of the product of the two predictors. Let's create this new variable and call it diskxnadd.   

```{r}
seabloom$diskxnadd <- seabloom$disk * seabloom$nadd

int <- "mass.above ~ disk + nadd + diskxnadd"
fit.int <- sem(int, data = seabloom)
summary(fit.int)
```

The results show a significant effect of both variables and their interaction.

Next, we model them as a composite:

```{r}
compint <-
"comp.int <~ 1 * disk + nadd + diskxnadd
mass.above ~ comp.int"

fit.compint <- sem(compint, data = seabloom)
summary(fit.compint, standardized = TRUE, rsq = TRUE)
```

The combined effect of the predictors is the `std.all` value for the regression (`r round(lavInspect(fit.compint, what = "std.all")$beta[2, 1], digits = 3)`).

### Full model
```{r}
int.full <-
"comp.int <~ 1 * disk + nadd + diskxnadd

mass.above ~ comp.int + rich + even + precip.mm
rich ~ nadd + precip.mm
even ~ nadd + precip.mm

rich ~~ even"

fit.int.full <- sem(int.full, data = seabloom)
summary(fit.int.full, fit.measures = TRUE, standardized = TRUE, rsq = TRUE)
```

Not the greatest fit in terms of $p$-value (`r round(fitmeasures(fit.int.full, "pvalue"), digits = 2)`), but really fine in terms of CFI (`r round(fitmeasures(fit.int.full, "cfi"), digits = 3)`).

## Multigroup fitting 

Another way to incorporate interactions is to fit SEMs where coefficients can vary among groups. Lavaan offers the "group" argument to specify for which groups coefficients should be estimated. Importantly, groups have to be of categorical nature. For our dataset, the application of the disturbance ("yes" vs "no") is categorical. So let's fit the SEM to the two disturbance regimes:

```{r}
int.mg <-
"mass.above ~ rich + even + precip.mm
rich ~ nadd + precip.mm
even ~ nadd + precip.mm

rich ~~ even"

fit.int.mg <- sem(int.mg, group = "disk", data = seabloom)
summary(fit.int.mg, standardized = TRUE, rsq = TRUE)
```

The default option is to let all coefficients vary between groups, but have the same structure of direct and indirect effects. Let's visualize the estimated coefficients:

```{r, results=F}
fit_tab <- (summary(fit.int.mg, standardized = TRUE, rsq = TRUE))$PE
fit_tab$term <- paste0(fit_tab$lhs, " ", fit_tab$op, " ", fit_tab$rhs)
fit_tab$group_chr <- ifelse(fit_tab$group == 1, "undist", 
                            ifelse(fit_tab$group == 2, "dist", NA))

ggplot(data=subset(fit_tab, op == "~"), aes(y=est, x=group_chr, colour=group_chr)) + 
  geom_point(size=1) + geom_errorbar(aes(ymin = est-se*1.96, ymax = est+se*1.96)) + 
  facet_wrap(~term, scales="free") + 
  scale_colour_manual(values = c("blue",  "red")) + 
  geom_hline(aes(yintercept = 0), colour = "black", linetype = "dashed") + 
  guides(colour="none") +
  theme_bw() 
```

Each facet grid shows a path and the estimated coefficients, one for disturbed (in blue) and one for the undisturbed plots (in red).

To test equality constraints, such as same means of coefficients among groups, lavaan offers the "group.equal" argument:

```{r, results = 'asis'}
group.equal=c(
"intercepts",
"means",
"regressions",
"residuals",
"residual.covariances")

#fit.int.mg <- sem(int.mg, group = "disk", group.equal = c("regressions"), data = seabloom)
```

Furthermore, we can test equality constraints by labeling parameters. To do so, we provide namees for the path coefficients that we want to be equal for both groups (e.g. "b1"), whereas path coefficients that we want to vary between groups have different names (e.g., "b4a" and "b4b").

```{r}
int.mg.constrain <-
"mass.above ~  c('b1', 'b1') * rich + c('b2', 'b2') * even + c('b3', 'b3') * precip.mm
rich ~ c('b4a', 'b4b') * nadd + c('b5', 'b5') * precip.mm
even ~ c('b6a', 'b6b') *  nadd + c('b7', 'b7') * precip.mm

rich ~~ even"

fit.int.mg.constrain <- sem(int.mg.constrain, group = "disk", data = seabloom)
summary(fit.int.mg.constrain, standardized = TRUE, rsq = TRUE)
```

Let's visualize again the coefficients to see the effect:

```{r, results=F}
fit_tab <- (summary(fit.int.mg.constrain, standardized = TRUE, rsq = TRUE))$PE
fit_tab$term <- paste0(fit_tab$lhs, " ", fit_tab$op, " ", fit_tab$rhs)
fit_tab$group_chr <- ifelse(fit_tab$group == 1, "undist", 
                            ifelse(fit_tab$group == 2, "dist", NA))

ggplot(data=subset(fit_tab, op == "~"), aes(y=est, x=group_chr, colour=group_chr)) + 
  geom_point(size=1) + geom_errorbar(aes(ymin = est-se*1.96, ymax = est+se*1.96)) + 
  facet_wrap(~term, scales="free") + 
  scale_colour_manual(values = c("blue",  "red")) + 
  geom_hline(aes(yintercept = 0), colour = "black", linetype = "dashed") + 
  guides(colour="none") +
  theme_bw() 
```

Model comparison with AICc indicates that the disturbance effect probably interacts with more than the nitrogen addition. 

```{r}
library(AICcmodavg)
aictab(list(fit.int.mg, fit.int.mg.constrain))
```

# Complex sampling structure
Often, we encounter more complex sampling or experimental schemes, e.g. the data is nested within sites or contains groups with non-random differences such as sexes or lifestages.
As a result, these data violate the principle of being [*i.i.d.* (independent and identically distributed)](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables).
Thus, it is necessary to account for this structure in the data in the model.


The add-on package [`lavaan.survey`](https://cran.r-project.org/web/packages/lavaan.survey/index.html) allows the analysis of stratified, clustered or weighted data with the help of the package [`survey`](https://r-survey.r-forge.r-project.org/survey/).
With this, `lavaan` objects can be processed further with a specific data structure:
first, we initialize the design and then, post-process the `lavaan` object and compute the adjusted results.
The result is a corrected `lavaan` object.

```{r, message=FALSE}
library("lavaan.survey")
```

As sampling was performed in `r length(unique(seabloom$plot))` plots nested in three  different fields (`A`, `B` and `C`), let's adjust for this structure.
For this, we first specify the study design as plots (`ids`) to be nested within fields (`strata`).

```{r}
design <- svydesign(ids = ~ plot, strata = ~ field, nest = TRUE, 
                    data = seabloom)
summary(design)
```

Next, we can refit the `simple` model from before with `lavaan.survey` using the specified study design as an argument.

```{r}
fit.simple.nest <- lavaan.survey(lavaan.fit = fit.simple,
                                 survey.design = design)
summary(fit.simple.nest, rsq = TRUE)
```

We see that the robust $p$-value increased substantially from `r round(fitmeasures(fit.simple, "pvalue.scaled"), digits = 2)` to `r round(fitmeasures(fit.simple.nest, "pvalue.scaled"), digits = 2)`, while the R^2^, the estimates and their standard errors remained basically the same.


# Spatial autocorrelation
We can detect spatial autocorrelation in this analysis with the help of a script developped by Jarret Byrnes...

First, download the script if absent and load it.
```{r}
if(!file.exists("lavSpatialCorrect.R"))
  {system("wget https://raw.githubusercontent.com/jebyrnes/spatial_correction_lavaan/master/lavSpatialCorrect.R")}

if(!file.exists("lavSpatialCorrect.R"))
  {system("wget https://raw.githubusercontent.com/jebyrnes/spatial_correction_lavaan/master/predict_lavaan.R")}

source(here("lavSpatialCorrect.R"))
source(here("predict_lavaan.R"))
```

## Geographical coordinates
To account for spatial autocorrelation, we first need the coordinates of the respective fields. As none are given in the publication, we use approximated location inferred from the map in the supplementary.

```{r}
library(tidyverse)
seabloom_A <- seabloom %>% filter(field == "A") %>% mutate(lat = 45.4232 + rnorm(n(), mean=0, .1),
                                               lon = -93.197 + rnorm(n(), mean=0, .001))

seabloom_B <- seabloom %>% filter(field == "B") %>% mutate(lat = 45.4258 + rnorm(n(), mean=0, .1),
                                               lon = -93.2102 + rnorm(n(), mean=0, .001))

seabloom_C <- seabloom %>% filter(field == "C") %>% mutate(lat = 45.3969 + rnorm(n(), mean=0, .1),
                                               lon = -93.1933 + rnorm(n(), mean=0, .001))

seabloom <- bind_rows(seabloom_A, seabloom_B, seabloom_C)
```


## Correct for spatial autocorrelation
"lavSpatialCorrect calculates Moran's I for the residuals of all endogenous variables, and then spatially corrects them via Moran's I. If they are spatially independent, the effective sample size = the true sample size."

```{r}


predict_lavaan <- function(fit, newdata = NULL){
  stopifnot(inherits(fit, "lavaan"))
  
  #Make sure we can use this
  if(!inspect(fit, "meanstructure")) stop("Need to supply meanstructure = TRUE in fit\n")
  if(is.null(newdata)){
    newdata <- data.frame(inspect(fit, "data"))
    names(newdata) <- lavNames(fit)
  }
  
  if(length(lavNames(fit, type="lv"))!=0) stop("Does not currently work with latent variables\n")
  
  #check for new data
  if(sum(!(lavNames(fit, type="ov.x") %in% names(newdata)))>0) stop("Not all exogenous variables supplied!")
  
  #Add some new columns to newdata
  newdata$Intercept <- 1
  newdata[lavNames(fit, "ov.nox")] <- 0
  
  
  mod_df <- data.frame(lhs = fit@ParTable$lhs,
                       op = fit@ParTable$op,
                       rhs = fit@ParTable$rhs,
                       exo = fit@ParTable$exo,
                       est = fit@ParTable$est,
                       se = fit@ParTable$se,
                       stringsAsFactors=FALSE)
  
  #Drop covariances
  mod_df <- mod_df[-which(mod_df$op=="~~"),]
  mod_df[which(mod_df$op=="~1"),]$rhs <- "Intercept"
  
  #get rid of exogenous on lhs
  mod_df <- mod_df[-which(mod_df$exo==1),]
  
  #Order by lhs
  mod_df <- mod_df[sort(mod_df$lhs, index.return=TRUE)$ix,]
  
  #let us know which variables on the rhs are exogenous
  mod_df$ord <- 0
  mod_df[which(!(mod_df$rhs %in% mod_df$lhs)),]$ord <- 1
  
  #Make a "order"
  ord_current <- 1
  while(sum(mod_df$ord==0)>0){
    for(r in unique(mod_df$lhs)){
      val <-  sum(mod_df[which(mod_df$lhs==r),]$ord==0)
      if(val==0) {
        mod_df[which(mod_df$lhs==r),]$ord <- ord_current
        
        if(sum(mod_df$rhs==r)>0)
          mod_df[which(mod_df$rhs==r),]$ord <- ord_current+1
      }
    }
  ord_current <- ord_current +1
  }
  
  #correct for ragged ordering
  for(r in unique(mod_df$lhs)){
    mod_df[which(mod_df$lhs==r),]$ord <- max(mod_df[which(mod_df$lhs==r),]$ord)
  }
  
  #sort by order 
  mod_df <- mod_df[sort(mod_df$ord, index.return=TRUE)$ix,]
  
  #now do the fitting in order
  fit_df <- data.frame(base = rep(1, nrow(newdata)))
  
  for(r in unique(mod_df$lhs)){
    subdf <- subset(mod_df, mod_df$lhs==r)
    #make a formula
    rhs <- paste0(subdf$rhs, collapse=" + ")
    form <- as.formula(paste0(r, " ~ ", rhs))
    
    #use formula to get right part of the data in right format
    mod_mat <- model.matrix(form, newdata)[,-1]
    new_val = mod_mat %*% subdf$est
    
    fit_df[[r]] <- new_val
    newdata[[r]] <- new_val
  }
  
  return(fit_df[,-1])
  
}

fitted_lavaan <- function(fit){
  predict_lavaan(fit)
}

residuals_lavaan <- function(fit){
  fitted_vals <- fitted_lavaan(fit)
  
  rawdata <- data.frame(inspect(fit, "data"))
  names(rawdata) <- lavNames(fit)
  
  res <- data.frame(base = rep(1, nrow(rawdata)))
  for(vals in names(fitted_vals)){
    res[[vals]] <- rawdata[[vals]] - fitted_vals[[vals]] 
  }
  
  return(res[,-1])
}


fit.simple2 <- sem(simple, data = seabloom, meanstructure=T)
summary(fit.simple2)

library(ggplot2)

# residuals are key for the analysis
fitRes <- as.data.frame(residuals_lavaan(fit.simple2))

seabloom$fitted.value <- fitted.values(fit.simple2, "casewise")[1]
seabloom$resid <- as.numeric(seabloom$mass.above - seabloom$fitted.value)

#raw visualization of NDVI residuals
ggplot(data=seabloom, aes(lat, lon, colour=resid)) + geom_point()
lavSpatialCorrect(fit.simple2, seabloom$lon, seabloom$lat)
```

# References

